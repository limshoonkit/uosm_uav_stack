{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12367a66",
   "metadata": {},
   "source": [
    "### 3- Helper for finding Transform & Timestamp needed from extrinsic calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e071b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scipy plotly pandas nbformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b699c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!source /opt/ros/humble/setup.bash"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21eee923",
   "metadata": {},
   "source": [
    "### From Kalibr for camera to imu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8799caef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "# cam0 to imu0 HD720 / 2 (640, 360) \n",
    "T_ic_cam0_HD720 = np.array([\n",
    "    [-0.02139781, -0.04509792,  0.99875338,  0.09553478],\n",
    "    [-0.9990368,  -0.0373147,  -0.0230888,   0.01664252],\n",
    "    [ 0.03830944, -0.99828543, -0.04425603, -0.03314106],\n",
    "    [ 0.,          0.,          0.,          1.        ]\n",
    "])\n",
    "\n",
    "# cam1 to imu0\n",
    "T_ic_cam1_HD720 = np.array([\n",
    "    [-0.02768216, -0.04476991,  0.99861372,  0.09508215],\n",
    "    [-0.99887051, -0.03735585, -0.02936402, -0.04580398],\n",
    "    [ 0.03861869, -0.99829865, -0.04368525, -0.03071331],\n",
    "    [ 0.,          0.,          0.,          1.        ]\n",
    "])\n",
    "\n",
    "# csi_cam to imu0\n",
    "T_ic_csi_cam = np.array([\n",
    "    [-0.01067075,  0.64499989,  0.76410816,  0.05320717],\n",
    "    [-0.99872944, -0.04451191,  0.02362622, -0.0016416 ],\n",
    "    [ 0.04925082, -0.76288521,  0.64465535,  0.07154415],\n",
    "    [ 0.,          0.,          0.,          1.        ]\n",
    "])\n",
    "\n",
    "# cam0 to imu0 VGA(672, 376) \n",
    "T_ic_cam0_vga = np.array([\n",
    "    [ 0.01327902, -0.08917957,  0.99592704,  0.08108838],\n",
    "    [-0.99990508,  0.00247407,  0.0135536,   0.03422853],\n",
    "    [-0.0036727,  -0.99601249, -0.08913825, -0.03896725],\n",
    "    [ 0.,          0.,          0.,          1.        ]\n",
    "])\n",
    "\n",
    "# cam1 to imu0\n",
    "T_ic_cam1_vga = np.array([\n",
    "    [ 0.01302763, -0.09208576,  0.99566585,  0.08183526],\n",
    "    [-0.99990832,  0.00247717,  0.01331224, -0.02849814],\n",
    "    [-0.0036923,  -0.995748,   -0.09204505, -0.03939789],\n",
    "    [ 0.,          0.,          0.,          1.        ]\n",
    "])\n",
    "\n",
    "def extract_origin(tform):\n",
    "    t = tform[:3, 3]\n",
    "    r = R.from_matrix(tform[:3, :3])\n",
    "    rpy = r.as_euler(\"xyz\", degrees=False)\n",
    "    return t, rpy\n",
    "\n",
    "# cam0\n",
    "xyz0, rpy0 = extract_origin(T_ic_cam0_HD720)\n",
    "# cam1\n",
    "xyz1, rpy1 = extract_origin(T_ic_cam1_HD720)\n",
    "\n",
    "# Print with 5 decimal precision\n",
    "print(\"----------------------------------------\")\n",
    "print(\"HD720 divided by 2 (640, 360) resolution\")\n",
    "print(\"----------------------------------------\")\n",
    "for name, xyz, rpy in [(\"cam0\", xyz0, rpy0), (\"cam1\", xyz1, rpy1)]:\n",
    "    print(f\"{name} xyz: {xyz.round(5).tolist()}\")\n",
    "    print(f\"{name} rpy: {rpy.round(5).tolist()}\")\n",
    "\n",
    "# cam0\n",
    "xyz0, rpy0 = extract_origin(T_ic_cam0_vga)\n",
    "# cam1\n",
    "xyz1, rpy1 = extract_origin(T_ic_cam1_vga)\n",
    "print(\"----------------------------------------\")\n",
    "print(\"VGA (672, 376) resolution\")\n",
    "print(\"----------------------------------------\")\n",
    "for name, xyz, rpy in [(\"cam0\", xyz0, rpy0), (\"cam1\", xyz1, rpy1)]:\n",
    "    print(f\"{name} xyz: {xyz.round(5).tolist()}\")\n",
    "    print(f\"{name} rpy: {rpy.round(5).tolist()}\")\n",
    "\n",
    "# CSI cam\n",
    "xyz, rpy = extract_origin(T_ic_csi_cam)\n",
    "print(\"----------------------------------------\")\n",
    "print(\"CSI cam\")\n",
    "print(\"----------------------------------------\")\n",
    "print(f\"csi_cam xyz: {xyz.round(5).tolist()}\")\n",
    "print(f\"csi_cam rpy: {rpy.round(5).tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e34bcf",
   "metadata": {},
   "source": [
    "### Find xacro from camera intrinsic and extrinsic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461662c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.float_ = np.float64 # NOTE: workaround for tf_transformations compatibility\n",
    "\n",
    "from tf_transformations import quaternion_from_euler, euler_from_matrix, translation_matrix, quaternion_matrix, inverse_matrix, translation_from_matrix\n",
    "\n",
    "kalibr_trans = [0.09553, 0.01664, -0.03314]\n",
    "kalibr_rpy = [-1.6151, -0.03832, -1.59221] # Roll, Pitch, Yaw\n",
    "\n",
    "# Convert Kalibr RPY to a quaternion, then a 4x4 matrix\n",
    "kalibr_quat = quaternion_from_euler(kalibr_rpy[0], kalibr_rpy[1], kalibr_rpy[2])\n",
    "T_optical_base = quaternion_matrix(kalibr_quat)\n",
    "T_optical_base[0:3, 3] = kalibr_trans\n",
    "\n",
    "camera_baseline = 0.06249531986870007\n",
    "camera_height = 0.0265\n",
    "\n",
    "# Transform from camera_link to camera_center\n",
    "T_center_camlink = translation_matrix([0, 0, camera_height / 2.0])\n",
    "\n",
    "# Transform from camera_center to left_camera_frame\n",
    "T_left_center = translation_matrix([0, camera_baseline / 2.0, 0])\n",
    "\n",
    "# Transform from left_camera_frame to left_camera_optical_frame\n",
    "optical_rpy = [-np.pi/2, 0, -np.pi/2]\n",
    "optical_quat = quaternion_from_euler(optical_rpy[0], optical_rpy[1], optical_rpy[2])\n",
    "T_optical_left = quaternion_matrix(optical_quat)\n",
    "\n",
    "# Get the full transform from camera_link to optical_frame\n",
    "# T_optical^cam_link = T_center^cam_link * T_left^center * T_optical^left\n",
    "T_optical_camlink = np.dot(T_center_camlink, np.dot(T_left_center, T_optical_left))\n",
    "\n",
    "# T_cam_link^base = T_optical^base * inv(T_optical^cam_link)\n",
    "T_camlink_base = np.dot(T_optical_base, inverse_matrix(T_optical_camlink))\n",
    "\n",
    "# Extract Final XYZ and RPY ---\n",
    "final_xyz = translation_from_matrix(T_camlink_base)\n",
    "final_rpy = euler_from_matrix(T_camlink_base, 'sxyz') # 'sxyz' for roll, pitch, yaw\n",
    "\n",
    "print(\"--- Final Transform for URDF (base_link -> camera_link) ---\")\n",
    "print(f\"XYZ (m): [{final_xyz[0]:.6f}, {final_xyz[1]:.6f}, {final_xyz[2]:.6f}]\")\n",
    "print(f\"RPY (rad): [{final_rpy[0]:.6f}, {final_rpy[1]:.6f}, {final_rpy[2]:.6f}]\")\n",
    "\n",
    "print(f'<origin xyz=\"{final_xyz[0]:.6f} {final_xyz[1]:.6f} {final_xyz[2]:.6f}\" rpy=\"{final_rpy[0]:.6f} {final_rpy[1]:.6f} {final_rpy[2]:.6f}\"/>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0535f7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from transforms3d.euler import euler2quat, quat2euler\n",
    "from transforms3d.quaternions import quat2mat\n",
    "from transforms3d.affines import compose\n",
    "\n",
    "def plot_frame_plotly(fig, T, label, length=0.05, line_width=4):\n",
    "    \"\"\"\n",
    "    Plots a 3D coordinate frame on a Plotly figure.\n",
    "    :param fig: Plotly figure object\n",
    "    :param T: 4x4 transformation matrix (numpy array)\n",
    "    :param label: Name of the frame\n",
    "    :param length: Length of the axis arrows\n",
    "    :param line_width: Width of the axis lines\n",
    "    \"\"\"\n",
    "    origin = T[0:3, 3]\n",
    "    R = T[0:3, 0:3]\n",
    "\n",
    "    # Define axis vectors\n",
    "    x_axis = R[:, 0] * length\n",
    "    y_axis = R[:, 1] * length\n",
    "    z_axis = R[:, 2] * length\n",
    "\n",
    "    # Add X-axis (red)\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=[origin[0], origin[0] + x_axis[0]],\n",
    "        y=[origin[1], origin[1] + x_axis[1]],\n",
    "        z=[origin[2], origin[2] + x_axis[2]],\n",
    "        mode='lines',\n",
    "        line=dict(color='red', width=line_width),\n",
    "        name=f'{label} X-axis',\n",
    "        showlegend=False\n",
    "    ))\n",
    "\n",
    "    # Add Y-axis (green)\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=[origin[0], origin[0] + y_axis[0]],\n",
    "        y=[origin[1], origin[1] + y_axis[1]],\n",
    "        z=[origin[2], origin[2] + y_axis[2]],\n",
    "        mode='lines',\n",
    "        line=dict(color='green', width=line_width),\n",
    "        name=f'{label} Y-axis',\n",
    "        showlegend=False\n",
    "    ))\n",
    "\n",
    "    # Add Z-axis (blue)\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=[origin[0], origin[0] + z_axis[0]],\n",
    "        y=[origin[1], origin[1] + z_axis[1]],\n",
    "        z=[origin[2], origin[2] + z_axis[2]],\n",
    "        mode='lines',\n",
    "        line=dict(color='blue', width=line_width),\n",
    "        name=f'{label} Z-axis',\n",
    "        showlegend=False\n",
    "    ))\n",
    "\n",
    "    # Add label text\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=[origin[0]], y=[origin[1]], z=[origin[2]],\n",
    "        mode='text',\n",
    "        text=[label],\n",
    "        textfont=dict(color='black', size=12),\n",
    "        textposition=\"top center\",\n",
    "        name=label,\n",
    "        showlegend=True\n",
    "    ))\n",
    "\n",
    "# Helper function to convert rpy to quaternion using transforms3d (quaternion_from_euler equivalent)\n",
    "def quaternion_from_euler(roll, pitch, yaw):\n",
    "    return euler2quat(roll, pitch, yaw, axes='sxyz') # static XYZ (intrinsic) or dynamic ZYX (extrinsic)\n",
    "\n",
    "# Helper function to create a translation matrix (translation_matrix equivalent)\n",
    "def translation_matrix(translation):\n",
    "    M = np.identity(4)\n",
    "    M[0:3, 3] = translation\n",
    "    return M\n",
    "\n",
    "# Helper function to create a quaternion matrix (quaternion_matrix equivalent)\n",
    "def quaternion_matrix(quat):\n",
    "    # transforms3d.quaternions.quat2mat returns a 3x3 rotation matrix\n",
    "    R = quat2mat(quat)\n",
    "    M = np.identity(4)\n",
    "    M[0:3, 0:3] = R\n",
    "    return M\n",
    "\n",
    "# Helper function to create transformation matrix from quaternion and translation\n",
    "def transform_from_quat_trans(quat, trans):\n",
    "    \"\"\"\n",
    "    Create 4x4 transformation matrix from quaternion and translation\n",
    "    :param quat: quaternion [qx, qy, qz, qw]\n",
    "    :param trans: translation [tx, ty, tz]\n",
    "    \"\"\"\n",
    "    # Convert quaternion [qx, qy, qz, qw] to [qw, qx, qy, qz] format for transforms3d\n",
    "    quat_transforms3d = [quat[3], quat[0], quat[1], quat[2]]  # [qw, qx, qy, qz]\n",
    "    T = quaternion_matrix(quat_transforms3d)\n",
    "    T[0:3, 3] = trans\n",
    "    return T\n",
    "\n",
    "# base_link is the origin (px4_imu)\n",
    "T_base_link = np.identity(4)\n",
    "\n",
    "# T_camlink^base\n",
    "T_camlink_trans = [0.094264, -0.015072, -0.045170]\n",
    "T_camlink_rpy = [-0.038358, 0.044271, -0.023112]\n",
    "T_camlink_quat = quaternion_from_euler(*T_camlink_rpy)\n",
    "T_camlink_base = quaternion_matrix(T_camlink_quat)\n",
    "T_camlink_base[0:3, 3] = T_camlink_trans\n",
    "\n",
    "# T_left_optical^base (from Kalibr)\n",
    "T_left_trans = [0.09553, 0.01664, -0.03314]\n",
    "T_left_rpy = [-1.6151, -0.03832, -1.59221]\n",
    "T_left_quat = quaternion_from_euler(*T_left_rpy)\n",
    "T_left_optical_base = quaternion_matrix(T_left_quat)\n",
    "T_left_optical_base[0:3, 3] = T_left_trans\n",
    "\n",
    "# T_right_optical^base (from Kalibr)\n",
    "T_right_trans = [0.09508, -0.0458, -0.03071]\n",
    "T_right_rpy = [-1.61453, -0.03863, -1.5985]\n",
    "T_right_quat = quaternion_from_euler(*T_right_rpy)\n",
    "T_right_optical_base = quaternion_matrix(T_right_quat)\n",
    "T_right_optical_base[0:3, 3] = T_right_trans\n",
    "\n",
    "# T_front_up_optical^base (from Kalibr)\n",
    "T_front_up_trans = [0.05321, -0.00164, 0.07154]\n",
    "T_front_up_rpy = [-0.8692, -0.04927, -1.58148]\n",
    "T_front_up_quat = quaternion_from_euler(*T_front_up_rpy)\n",
    "T_front_up_optical_base = quaternion_matrix(T_front_up_quat)\n",
    "T_front_up_optical_base[0:3, 3] = T_front_up_trans\n",
    "\n",
    "\n",
    "# T_lidar^left_cam (LiDAR to left camera transform)\n",
    "T_lidar_left_quat = [0.51857204, -0.51216204, 0.48526003, 0.48300703]  # [qx, qy, qz, qw]\n",
    "T_lidar_left_trans = [0.01281634, -0.12085161, -0.08237267]  # [tx, ty, tz]\n",
    "\n",
    "T_lidar_left_cam = transform_from_quat_trans(T_lidar_left_quat, T_lidar_left_trans)\n",
    "\n",
    "# Calculate T_lidar^base = T_left_optical^base * T_lidar^left_cam\n",
    "# NOTE: This assumes lidar->left_cam transform is relative to the left_cam_optical frame\n",
    "T_lidar_base = T_left_optical_base @ T_lidar_left_cam\n",
    "# Extract LiDAR to base_link RPY\n",
    "T_lidar_base_rotation = T_lidar_base[0:3, 0:3]\n",
    "# Convert rotation matrix to quaternion first, then to RPY\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "r = R.from_matrix(T_lidar_base_rotation)\n",
    "T_lidar_base_quat = r.as_quat()  # [qx, qy, qz, qw]\n",
    "T_lidar_base_rpy = r.as_euler('xyz', degrees=False)  # [roll, pitch, yaw] in radians\n",
    "\n",
    "# Print transform\n",
    "print(\"LiDAR to Left Camera Transform:\")\n",
    "print(\"Translation:\", T_lidar_left_trans)\n",
    "print(\"Quaternion [qx, qy, qz, qw]:\", T_lidar_left_quat)\n",
    "print(\"\\nLiDAR to base_link Transform:\")\n",
    "print(\"Translation [tx, ty, tz]:\", T_lidar_base[0:3, 3])\n",
    "print(\"Quaternion [qx, qy, qz, qw]:\", T_lidar_base_quat)\n",
    "print(\"RPY [roll, pitch, yaw] (radians):\", T_lidar_base_rpy)\n",
    "\n",
    "# Plot\n",
    "fig = go.Figure()\n",
    "\n",
    "# Plot each frame\n",
    "plot_frame_plotly(fig, T_base_link, 'base_link')\n",
    "plot_frame_plotly(fig, T_camlink_base, 'camera_link')\n",
    "plot_frame_plotly(fig, T_left_optical_base, 'left_cam_optical')\n",
    "plot_frame_plotly(fig, T_right_optical_base, 'right_cam_optical')\n",
    "plot_frame_plotly(fig, T_front_up_optical_base, 'front_up_cam_optical')\n",
    "plot_frame_plotly(fig, T_lidar_base, 'laser', length=0.08, line_width=3)\n",
    "\n",
    "# Update layout for 3D plot\n",
    "fig.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis_title='X (m)',\n",
    "        yaxis_title='Y (m)',\n",
    "        zaxis_title='Z (m)',\n",
    "        aspectmode='data', # Ensures equal aspect ratio\n",
    "    ),\n",
    "    title='Visualization of Camera and LiDAR TF Frames',\n",
    "    showlegend=True,\n",
    "    scene_camera=dict(\n",
    "        up=dict(x=0, y=0, z=1),  # Z-axis points upwards\n",
    "        center=dict(x=0, y=0, z=0), # Center of the view\n",
    "        eye=dict(x=1.5, y=1.5, z=1.5) # Camera position\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7587386",
   "metadata": {},
   "source": [
    "### For downwards rangesensor\n",
    "\n",
    "- Record data while stationary at different orientations:\n",
    "```\n",
    "Level (0°, 0°)\n",
    "Roll: -15°, -10°, -5°, +5°, +10°, +15°\n",
    "Pitch: -15°, -10°, -5°, +5°, +10°, +15°\n",
    "\n",
    "Hold each pose for 5-10 seconds to get stable readings\n",
    "```\n",
    "\n",
    "- Keep vehicle level, vary height:\n",
    "```\n",
    "0.5m, 1.0m, 1.5m, 2.0m above ground\n",
    "Hold each height for 5-10 seconds\n",
    "```\n",
    "\n",
    "- Dynamic movement:\n",
    "```\n",
    "Rectangular hover pattern with random attitude changes\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa197be",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transforms3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d597b174",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rosbag2_py\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import matplotlib.pyplot as plt\n",
    "from rclpy.serialization import deserialize_message\n",
    "from sensor_msgs.msg import Imu\n",
    "from sensor_msgs.msg import Range\n",
    "\n",
    "class RangeIMUCalibration:\n",
    "    def __init__(self, bag_path, imu_topic, range_topic):\n",
    "        self.bag_path = bag_path\n",
    "        self.imu_topic = imu_topic\n",
    "        self.range_topic = range_topic\n",
    "        \n",
    "        # Store synchronized data\n",
    "        self.imu_data = []\n",
    "        self.range_data = []\n",
    "        self.timestamps = []\n",
    "        \n",
    "        # Calibration parameters [tx, ty, tz, rx, ry, rz]\n",
    "        self.initial_guess = np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "        \n",
    "    def read_bag(self):\n",
    "        \"\"\"Read ROS2 bag and extract synchronized IMU and range data\"\"\"\n",
    "        reader = rosbag2_py.SequentialReader()\n",
    "        storage_options = rosbag2_py.StorageOptions(uri=self.bag_path, storage_id='sqlite3')\n",
    "        converter_options = rosbag2_py.ConverterOptions('', '')\n",
    "        reader.open(storage_options, converter_options)\n",
    "        \n",
    "        imu_msgs = {}\n",
    "        range_msgs = {}\n",
    "        \n",
    "        while reader.has_next():\n",
    "            (topic, data, timestamp) = reader.read_next()\n",
    "            \n",
    "            if topic == self.imu_topic:\n",
    "                msg = deserialize_message(data, Imu)\n",
    "                imu_msgs[timestamp] = msg\n",
    "                \n",
    "            elif topic == self.range_topic:\n",
    "                msg = deserialize_message(data, Range)\n",
    "                range_msgs[timestamp] = msg\n",
    "        \n",
    "        # Synchronize messages by timestamp\n",
    "        self.synchronize_messages(imu_msgs, range_msgs)\n",
    "        print(f\"Synchronized {len(self.timestamps)} message pairs\")\n",
    "        \n",
    "    def synchronize_messages(self, imu_msgs, range_msgs, tolerance=10e6):  # 10ms in nanoseconds\n",
    "        \"\"\"Synchronize IMU and range messages by timestamp\"\"\"\n",
    "        imu_times = sorted(imu_msgs.keys())\n",
    "        range_times = sorted(range_msgs.keys())\n",
    "        \n",
    "        for imu_time in imu_times:\n",
    "            # Find closest range message\n",
    "            closest_range_time = min(range_times, key=lambda x: abs(x - imu_time))\n",
    "            \n",
    "            if abs(imu_time - closest_range_time) <= tolerance:\n",
    "                # Extract IMU data\n",
    "                imu_msg = imu_msgs[imu_time]\n",
    "                orientation = [imu_msg.orientation.x, imu_msg.orientation.y, \n",
    "                             imu_msg.orientation.z, imu_msg.orientation.w]\n",
    "                \n",
    "                # Extract range data\n",
    "                range_msg = range_msgs[closest_range_time]\n",
    "                range_value = range_msg.range\n",
    "                \n",
    "                # Store valid measurements\n",
    "                if range_msg.min_range <= range_value <= range_msg.max_range:\n",
    "                    self.imu_data.append(orientation)\n",
    "                    self.range_data.append(range_value)\n",
    "                    self.timestamps.append(imu_time)\n",
    "                    \n",
    "    def transform_point(self, params):\n",
    "        \"\"\"Apply transformation to range sensor measurements\"\"\"\n",
    "        tx, ty, tz, rx, ry, rz = params\n",
    "        \n",
    "        # Translation vector\n",
    "        translation = np.array([tx, ty, tz])\n",
    "        \n",
    "        # Rotation matrix from Euler angles (roll, pitch, yaw)\n",
    "        rotation_matrix = R.from_euler('xyz', [rx, ry, rz]).as_matrix()\n",
    "        \n",
    "        transformed_ranges = []\n",
    "        \n",
    "        for i, (quat, measured_range) in enumerate(zip(self.imu_data, self.range_data)):\n",
    "            # Convert quaternion to rotation matrix (IMU orientation)\n",
    "            imu_rotation = R.from_quat(quat).as_matrix()\n",
    "            \n",
    "            # Range sensor measurement in sensor frame (assume pointing down -Z)\n",
    "            range_vector_sensor = np.array([0, 0, -measured_range])\n",
    "            \n",
    "            # Transform to IMU frame\n",
    "            range_vector_imu = rotation_matrix @ range_vector_sensor + translation\n",
    "            \n",
    "            # Transform to world frame using IMU orientation\n",
    "            range_vector_world = imu_rotation @ range_vector_imu\n",
    "            \n",
    "            # Expected ground height (assuming flat surface at z=0)\n",
    "            # The Z component should be consistent for flat ground\n",
    "            transformed_ranges.append(range_vector_world[2])\n",
    "            \n",
    "        return np.array(transformed_ranges)\n",
    "    \n",
    "    def cost_function(self, params):\n",
    "        \"\"\"Cost function for calibration optimization\"\"\"\n",
    "        transformed_ranges = self.transform_point(params)\n",
    "        \n",
    "        # For flat surface, all Z values should be similar\n",
    "        # Cost is variance of ground height estimates\n",
    "        cost = np.var(transformed_ranges)\n",
    "        \n",
    "        # Add regularization to prevent extreme parameters\n",
    "        reg_weight = 0.01\n",
    "        cost += reg_weight * np.sum(params**2)\n",
    "        \n",
    "        return cost\n",
    "    \n",
    "    def calibrate(self):\n",
    "        \"\"\"Perform extrinsic calibration optimization\"\"\"\n",
    "        print(\"Starting calibration optimization...\")\n",
    "        \n",
    "        # Bounds for parameters\n",
    "        bounds = [\n",
    "            (-0.15, 0.15),   # tx\n",
    "            (-0.15, 0.15),   # ty\n",
    "            (-0.15, 0.15),   # tz\n",
    "            (-np.pi/6, np.pi/6),  # rx\n",
    "            (-np.pi/6, np.pi/6),  # ry\n",
    "            (-np.pi/6, np.pi/6),  # rz\n",
    "        ]\n",
    "        \n",
    "        # Run optimization\n",
    "        result = minimize(\n",
    "            self.cost_function,\n",
    "            self.initial_guess,\n",
    "            method='L-BFGS-B',\n",
    "            bounds=bounds,\n",
    "            options={'maxiter': 1000}\n",
    "        )\n",
    "        \n",
    "        if result.success:\n",
    "            print(\"Calibration successful!\")\n",
    "            tx, ty, tz, rx, ry, rz = result.x\n",
    "            \n",
    "            print(f\"\\nExtrinsic calibration parameters:\")\n",
    "            print(f\"Translation (m): [{tx:.4f}, {ty:.4f}, {tz:.4f}]\")\n",
    "            print(f\"Rotation (rad): [{rx:.4f}, {ry:.4f}, {rz:.4f}]\")\n",
    "            print(f\"Rotation (deg): [{np.degrees(rx):.2f}, {np.degrees(ry):.2f}, {np.degrees(rz):.2f}]\")\n",
    "            print(f\"Final cost: {result.fun:.6f}\")\n",
    "            \n",
    "            # Generate ROS2 static transform publisher command\n",
    "            self.generate_tf_static_command(tx, ty, tz, rx, ry, rz)\n",
    "            \n",
    "            return result.x\n",
    "        else:\n",
    "            print(\"Calibration failed!\")\n",
    "            print(result.message)\n",
    "            return None\n",
    "    \n",
    "    def generate_tf_static_command(self, tx, ty, tz, rx, ry, rz):\n",
    "        \"\"\"Generate ROS2 static transform publisher command\"\"\"\n",
    "        # Convert Euler angles to quaternion\n",
    "        quat = R.from_euler('xyz', [rx, ry, rz]).as_quat()\n",
    "        \n",
    "        print(f\"\\nROS2 static transform publisher command:\")\n",
    "        print(f\"ros2 run tf2_ros static_transform_publisher \"\n",
    "              f\"{tx:.4f} {ty:.4f} {tz:.4f} \"\n",
    "              f\"{quat[0]:.4f} {quat[1]:.4f} {quat[2]:.4f} {quat[3]:.4f} \"\n",
    "              f\"base_link range_sensor\")\n",
    "              \n",
    "        print(f\"\\nURDF/SDF format:\")\n",
    "        print(f\"<origin xyz='{tx:.4f} {ty:.4f} {tz:.4f}' \"\n",
    "              f\"rpy='{rx:.4f} {ry:.4f} {rz:.4f}' />\")\n",
    "    \n",
    "    def validate_calibration(self, params):\n",
    "        \"\"\"Validate calibration results\"\"\"\n",
    "        transformed_ranges = self.transform_point(params)\n",
    "        \n",
    "        print(f\"\\nValidation results:\")\n",
    "        print(f\"Ground height std dev: {np.std(transformed_ranges):.4f} m\")\n",
    "        print(f\"Ground height mean: {np.mean(transformed_ranges):.4f} m\")\n",
    "        print(f\"Ground height range: [{np.min(transformed_ranges):.4f}, {np.max(transformed_ranges):.4f}] m\")\n",
    "        \n",
    "        # Plot results\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        plt.subplot(2, 2, 1)\n",
    "        plt.plot(transformed_ranges)\n",
    "        plt.title('Estimated Ground Height')\n",
    "        plt.ylabel('Height (m)')\n",
    "        plt.xlabel('Sample')\n",
    "        \n",
    "        plt.subplot(2, 2, 2)\n",
    "        plt.hist(transformed_ranges, bins=30)\n",
    "        plt.title('Ground Height Distribution')\n",
    "        plt.xlabel('Height (m)')\n",
    "        plt.ylabel('Count')\n",
    "        \n",
    "        plt.subplot(2, 2, 3)\n",
    "        plt.plot(self.range_data)\n",
    "        plt.title('Raw Range Measurements')\n",
    "        plt.ylabel('Range (m)')\n",
    "        plt.xlabel('Sample')\n",
    "        \n",
    "        plt.subplot(2, 2, 4)\n",
    "        # Plot IMU orientations (roll, pitch)\n",
    "        orientations = [R.from_quat(q).as_euler('xyz') for q in self.imu_data]\n",
    "        orientations = np.array(orientations)\n",
    "        plt.plot(np.degrees(orientations[:, 0]), label='Roll')\n",
    "        plt.plot(np.degrees(orientations[:, 1]), label='Pitch')\n",
    "        plt.title('IMU Orientation')\n",
    "        plt.ylabel('Angle (deg)')\n",
    "        plt.xlabel('Sample')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def main():\n",
    "    # Paths\n",
    "    bag_path = \"../bags/calib_range1\"\n",
    "    imu_topic = \"/mavros/imu/data\"\n",
    "    range_topic = \"/mavros/hps167_pub\"\n",
    "    \n",
    "    # Initialize calibration\n",
    "    calibrator = RangeIMUCalibration(bag_path, imu_topic, range_topic)\n",
    "    \n",
    "    # Read bag data\n",
    "    calibrator.read_bag()\n",
    "    \n",
    "    if len(calibrator.timestamps) < 100:\n",
    "        print(\"Warning: Limited data points. Consider collecting more data.\")\n",
    "    \n",
    "    # Perform calibration\n",
    "    result = calibrator.calibrate()\n",
    "    \n",
    "    if result is not None:\n",
    "        # Validate results\n",
    "        calibrator.validate_calibration(result)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784973cc",
   "metadata": {},
   "source": [
    "### 2D Lidar Scan to Zed SDK PoinCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef290486",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install open3d opencv-python==4.10.0.82"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c3d410",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "LiDAR-Camera-IMU Extrinsic Calibration using Open3D optimization\n",
    "Outputs URDF parameters for rplidar joint\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import rosbag2_py\n",
    "from rclpy.serialization import deserialize_message\n",
    "from sensor_msgs.msg import LaserScan, PointCloud2, Image, Imu\n",
    "import sensor_msgs_py.point_cloud2 as pc2\n",
    "from geometry_msgs.msg import TransformStamped\n",
    "import cv2\n",
    "from cv_bridge import CvBridge\n",
    "from scipy.optimize import minimize\n",
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "class LiDARCalibratorOptimizer:\n",
    "    def __init__(self, bag_path):\n",
    "        self.bag_path = bag_path\n",
    "        self.bridge = CvBridge()\n",
    "        \n",
    "        # Kalibr calibration results\n",
    "        self.T_cam0_imu = np.array([\n",
    "            [ 0.05518993, -0.095478, 0.99390041, 0.09185485],\n",
    "            [-0.9982956, 0.0136382, 0.05674413, 0.03547225],\n",
    "            [-0.01897283, -0.99533811, -0.09456258, -0.03660268],\n",
    "            [ 0., 0., 0., 1.]\n",
    "        ])\n",
    "        \n",
    "        # Data storage\n",
    "        self.laser_scans = []\n",
    "        self.point_clouds = []\n",
    "        self.imu_data = []\n",
    "        self.timestamps = defaultdict(list)\n",
    "        \n",
    "        # Initial guess for LiDAR pose (modify based on your mounting)\n",
    "        self.initial_guess = [0.0, 0.0, 0.1, 0.0, 0.0, 0.0]  # [x, y, z, roll, pitch, yaw]\n",
    "        \n",
    "    def load_bag_data(self):\n",
    "        \"\"\"Load synchronized data from ROS2 bag\"\"\"\n",
    "        storage_options = rosbag2_py.StorageOptions(uri=self.bag_path, storage_id='sqlite3')\n",
    "        converter_options = rosbag2_py.ConverterOptions(\n",
    "            input_serialization_format='cdr',\n",
    "            output_serialization_format='cdr'\n",
    "        )\n",
    "        \n",
    "        reader = rosbag2_py.SequentialReader()\n",
    "        reader.open(storage_options, converter_options)\n",
    "        \n",
    "        topic_types = reader.get_all_topics_and_types()\n",
    "        type_map = {topic.name: topic.type for topic in topic_types}\n",
    "        \n",
    "        while reader.has_next():\n",
    "            topic, data, timestamp = reader.read_next()\n",
    "            \n",
    "            if topic == '/scan':\n",
    "                msg = deserialize_message(data, LaserScan)\n",
    "                self.laser_scans.append((timestamp, msg))\n",
    "                self.timestamps['laser'].append(timestamp)\n",
    "                \n",
    "            elif topic == '/zed_node/point_cloud/cloud_registered':\n",
    "                msg = deserialize_message(data, PointCloud2)\n",
    "                self.point_clouds.append((timestamp, msg))\n",
    "                self.timestamps['pointcloud'].append(timestamp)\n",
    "                \n",
    "            elif topic == '/mavros/imu/data':\n",
    "                msg = deserialize_message(data, Imu)\n",
    "                self.imu_data.append((timestamp, msg))\n",
    "                self.timestamps['imu'].append(timestamp)\n",
    "        \n",
    "        print(f\"Loaded: {len(self.laser_scans)} laser, {len(self.point_clouds)} pointcloud, {len(self.imu_data)} IMU\")\n",
    "    \n",
    "    def synchronize_data(self, time_tolerance=5e7):  # 50ms tolerance\n",
    "        \"\"\"Find temporally synchronized sensor data\"\"\"\n",
    "        synced_data = []\n",
    "        time_offsets = []\n",
    "        \n",
    "        for pc_ts, pc_msg in self.point_clouds:\n",
    "            # Find closest laser scan\n",
    "            laser_diffs = [abs(ls_ts - pc_ts) for ls_ts, _ in self.laser_scans]\n",
    "            if min(laser_diffs) < time_tolerance:\n",
    "                laser_idx = laser_diffs.index(min(laser_diffs))\n",
    "                laser_ts, laser_msg = self.laser_scans[laser_idx]\n",
    "                \n",
    "                # Find closest IMU\n",
    "                imu_diffs = [abs(imu_ts - pc_ts) for imu_ts, _ in self.imu_data]\n",
    "                if min(imu_diffs) < time_tolerance:\n",
    "                    imu_idx = imu_diffs.index(min(imu_diffs))\n",
    "                    imu_ts, imu_msg = self.imu_data[imu_idx]\n",
    "                    \n",
    "                    time_offset = (laser_ts - pc_ts) * 1e-9  # Convert to seconds\n",
    "                    time_offsets.append(time_offset)\n",
    "                    \n",
    "                    synced_data.append({\n",
    "                        'timestamp': pc_ts,\n",
    "                        'pointcloud': pc_msg,\n",
    "                        'laser': laser_msg,\n",
    "                        'imu': imu_msg,\n",
    "                        'time_diffs': {'laser': laser_ts - pc_ts, 'imu': imu_ts - pc_ts}\n",
    "                    })\n",
    "        \n",
    "        if time_offsets:\n",
    "            avg_offset = np.mean(time_offsets)\n",
    "            std_offset = np.std(time_offsets)\n",
    "            print(f\"Average time offset (laser - pointcloud): {avg_offset:.6f} ± {std_offset:.6f} seconds\")\n",
    "            print(f\"Found {len(synced_data)} synchronized measurements\")\n",
    "        \n",
    "        return synced_data\n",
    "    \n",
    "    def laser_to_points(self, laser_msg, z_height=None):\n",
    "        \"\"\"Convert LaserScan to 3D points\"\"\"\n",
    "        # Use initial guess z offset if z_height not provided\n",
    "        if z_height is None:\n",
    "            z_height = self.initial_guess[2]  # Use initial z guess\n",
    "        \n",
    "        angles = np.arange(laser_msg.angle_min, laser_msg.angle_max + laser_msg.angle_increment, \n",
    "                          laser_msg.angle_increment)\n",
    "        ranges = np.array(laser_msg.ranges)\n",
    "        \n",
    "        # Filter valid ranges\n",
    "        valid_idx = (ranges >= laser_msg.range_min) & (ranges <= laser_msg.range_max) & np.isfinite(ranges)\n",
    "        angles = angles[valid_idx]\n",
    "        ranges = ranges[valid_idx]\n",
    "        \n",
    "        # Convert to cartesian\n",
    "        x = ranges * np.cos(angles)\n",
    "        y = ranges * np.sin(angles)\n",
    "        z = np.full_like(x, z_height)\n",
    "        \n",
    "        return np.column_stack((x, y, z))\n",
    "    \n",
    "    def pointcloud_to_numpy(self, pc_msg):\n",
    "        \"\"\"Convert ROS PointCloud2 to numpy array\"\"\"\n",
    "        points = []\n",
    "        for point in pc2.read_points(pc_msg, field_names=(\"x\", \"y\", \"z\"), skip_nans=True):\n",
    "            points.append([point[0], point[1], point[2]])\n",
    "        return np.array(points)\n",
    "    \n",
    "    def transform_points(self, points, transform_params):\n",
    "        \"\"\"Apply transformation to points\"\"\"\n",
    "        x, y, z, roll, pitch, yaw = transform_params\n",
    "        \n",
    "        # Create transformation matrix\n",
    "        R_x = np.array([[1, 0, 0], [0, np.cos(roll), -np.sin(roll)], [0, np.sin(roll), np.cos(roll)]])\n",
    "        R_y = np.array([[np.cos(pitch), 0, np.sin(pitch)], [0, 1, 0], [-np.sin(pitch), 0, np.cos(pitch)]])\n",
    "        R_z = np.array([[np.cos(yaw), -np.sin(yaw), 0], [np.sin(yaw), np.cos(yaw), 0], [0, 0, 1]])\n",
    "        \n",
    "        R = R_z @ R_y @ R_x\n",
    "        t = np.array([x, y, z])\n",
    "        \n",
    "        return (R @ points.T).T + t\n",
    "    \n",
    "    def compute_icp_cost(self, laser_points, pc_points):\n",
    "        \"\"\"Compute ICP-style alignment cost\"\"\"\n",
    "        if len(laser_points) == 0 or len(pc_points) == 0:\n",
    "            return float('inf')\n",
    "        \n",
    "        # Create Open3D point clouds\n",
    "        laser_pcd = o3d.geometry.PointCloud()\n",
    "        laser_pcd.points = o3d.utility.Vector3dVector(laser_points)\n",
    "        \n",
    "        pc_pcd = o3d.geometry.PointCloud()\n",
    "        pc_pcd.points = o3d.utility.Vector3dVector(pc_points)\n",
    "        \n",
    "        # Downsample for efficiency\n",
    "        if len(pc_points) > 5000:\n",
    "            pc_pcd = pc_pcd.voxel_down_sample(0.05)\n",
    "        \n",
    "        # Compute nearest neighbor distances\n",
    "        distances = laser_pcd.compute_point_cloud_distance(pc_pcd)\n",
    "        return np.mean(distances)\n",
    "    \n",
    "    def project_pointcloud_to_2d(self, points, z_range=(-0.2, 0.2)):\n",
    "        \"\"\"Project 3D pointcloud to 2D laser scan plane\"\"\"\n",
    "        # Filter points near laser height\n",
    "        mask = (points[:, 2] >= z_range[0]) & (points[:, 2] <= z_range[1])\n",
    "        if np.sum(mask) == 0:\n",
    "            return np.array([]).reshape(0, 3)\n",
    "        \n",
    "        filtered_points = points[mask]\n",
    "        # Set Z to laser plane\n",
    "        filtered_points[:, 2] = 0.0\n",
    "        return filtered_points\n",
    "    \n",
    "    def objective_function(self, params, synced_data):\n",
    "        \"\"\"Optimization objective function\"\"\"\n",
    "        total_cost = 0.0\n",
    "        valid_pairs = 0\n",
    "        \n",
    "        for data in synced_data[:min(50, len(synced_data))]:  # Limit for speed\n",
    "            # Transform laser points to camera frame\n",
    "            laser_points = self.laser_to_points(data['laser'])\n",
    "            if len(laser_points) == 0:\n",
    "                continue\n",
    "                \n",
    "            # Apply current transformation guess\n",
    "            transformed_laser = self.transform_points(laser_points, params)\n",
    "            \n",
    "            # Transform to camera frame (laser -> imu -> camera)\n",
    "            laser_in_camera = (self.T_cam0_imu @ np.hstack([transformed_laser, np.ones((len(transformed_laser), 1))]).T).T[:, :3]\n",
    "            \n",
    "            # Get pointcloud data\n",
    "            pc_points = self.pointcloud_to_numpy(data['pointcloud'])\n",
    "            if len(pc_points) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Project pointcloud to laser plane for comparison\n",
    "            pc_2d = self.project_pointcloud_to_2d(pc_points)\n",
    "            if len(pc_2d) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Compute alignment cost\n",
    "            cost = self.compute_icp_cost(laser_in_camera, pc_2d)\n",
    "            if not np.isinf(cost):\n",
    "                total_cost += cost\n",
    "                valid_pairs += 1\n",
    "        \n",
    "        if valid_pairs == 0:\n",
    "            return float('inf')\n",
    "        \n",
    "        return total_cost / valid_pairs\n",
    "    \n",
    "    def optimize_extrinsics(self, synced_data):\n",
    "        \"\"\"Optimize LiDAR extrinsic parameters\"\"\"\n",
    "        print(\"Starting optimization...\")\n",
    "        \n",
    "        # Bounds for optimization (reasonable physical constraints)\n",
    "        bounds = [\n",
    "            (-0.25, 0.25),   # x translation\n",
    "            (-0.25, 0.25),   # y translation\n",
    "            (-0.25, 0.25),   # z translation\n",
    "            (-np.pi/6, np.pi/6),  # roll\n",
    "            (-np.pi/6, np.pi/6),  # pitch\n",
    "            (-np.pi/6, np.pi/6)       # yaw\n",
    "        ]\n",
    "        \n",
    "        result = minimize(\n",
    "            self.objective_function,\n",
    "            self.initial_guess,\n",
    "            args=(synced_data,),\n",
    "            bounds=bounds,\n",
    "            method='L-BFGS-B',\n",
    "            options={'maxiter': 100, 'disp': True}\n",
    "        )\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def run_calibration(self):\n",
    "        \"\"\"Main calibration pipeline\"\"\"\n",
    "        print(\"Loading bag data...\")\n",
    "        self.load_bag_data()\n",
    "        \n",
    "        print(\"Synchronizing sensor data...\")\n",
    "        synced_data = self.synchronize_data()\n",
    "        \n",
    "        if len(synced_data) < 10:\n",
    "            print(\"Warning: Very few synchronized measurements found!\")\n",
    "            return None\n",
    "        \n",
    "        print(\"Running optimization...\")\n",
    "        result = self.optimize_extrinsics(synced_data)\n",
    "        \n",
    "        if result.success:\n",
    "            print(f\"\\nOptimization converged!\")\n",
    "            print(f\"Final cost: {result.fun:.6f}\")\n",
    "            print(f\"Parameters: {result.x}\")\n",
    "            \n",
    "            return result.x\n",
    "        else:\n",
    "            print(f\"Optimization failed: {result.message}\")\n",
    "            return None\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Usage\n",
    "    bag_path = \"../bags/calib_zed_720_lidar\"\n",
    "    \n",
    "    calibrator = LiDARCalibratorOptimizer(bag_path)\n",
    "    \n",
    "    # Set initial guess based on sensor mounting\n",
    "    calibrator.initial_guess = [0.0, 0.03, 0.07, 0.0, 0.0, 0.0]  # [x, y, z, roll, pitch, yaw]\n",
    "    \n",
    "    result = calibrator.run_calibration()\n",
    "    \n",
    "    if result is not None:\n",
    "        print(\"Calibration completed successfully!\")\n",
    "        print(\"Check 'lidar_extrinsics.urdf.xacro' for URDF parameters\")\n",
    "    else:\n",
    "        print(\"Calibration failed!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
